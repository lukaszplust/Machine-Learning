{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtlUDw2DR4VVqrf2haiCn/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukaszplust/Machine-Learning/blob/main/Lab_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TO RUN THIS FILE ADD [file_name].txt with that:\n",
        "\n",
        "from decision_tree import DecisionTree\n",
        "\n",
        "from random_forest_solution import RandomForest\n",
        "\n",
        "from load_data import generate_data, load_titanic\n",
        "\n",
        "from node_solution import Node"
      ],
      "metadata": {
        "id": "yvwznhLV6fha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "decision_tree"
      ],
      "metadata": {
        "id": "veRK1zk72fHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N0wY99Tu1Rw9"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, params):\n",
        "        self.root_node = Node()\n",
        "        self.params = defaultdict(lambda: None, params)\n",
        "\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.root_node.train(X, y, self.params)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predicted = self.predict(X)\n",
        "        predicted = [round(p) for p in predicted]\n",
        "        print(f\"Accuracy: {round(np.mean(predicted==y),2)}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        prediction = []\n",
        "        for x in X:\n",
        "            prediction.append(self.root_node.predict(x))\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load_data.py"
      ],
      "metadata": {
        "id": "qyGtGCMw2dJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "def generate_data():\n",
        "    TRAIN_SAMPLES = 100\n",
        "    TEST_SAMPLES = 20\n",
        "    FEATURE_DIM = 5\n",
        "\n",
        "    X_train = np.random.rand(TRAIN_SAMPLES, FEATURE_DIM)\n",
        "    y_train = np.random.binomial(1, 0.5, TRAIN_SAMPLES)\n",
        "    X_test = np.random.rand(TEST_SAMPLES, FEATURE_DIM)\n",
        "    y_test = np.random.binomial(1, 0.5, TEST_SAMPLES)\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "\n",
        "def load_titanic():\n",
        "    data = pd.read_csv(\"titanic.csv\")\n",
        "    data = data[[\"Pclass\", \"Fare\", \"Parch\", \"SibSp\", \"Age\", \"Sex\", \"Survived\"]]\n",
        "    data = data.dropna().reset_index(drop=True)\n",
        "    data[\"Sex\"] = [1 if sex == \"female\" else 0 for sex in data[\"Sex\"]]\n",
        "    test_idx = np.random.choice(range(data.shape[0]), round(0.2*data.shape[0]), replace=False)\n",
        "    data_test = data.iloc[test_idx, :]\n",
        "    data_train = data.drop(test_idx, axis=0)\n",
        "    X_train = data_train.drop(\"Survived\", axis=1).to_numpy()\n",
        "    y_train = data_train[\"Survived\"].to_numpy()\n",
        "    X_test = data_test.drop(\"Survived\", axis=1).to_numpy()\n",
        "    y_test = data_test[\"Survived\"].to_numpy()\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ],
      "metadata": {
        "id": "53PEGEHF1SmO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "node.py"
      ],
      "metadata": {
        "id": "oEnFWRib2v5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Node:\n",
        "    def __init__(self):\n",
        "        self.left_child = None\n",
        "        self.right_child = None\n",
        "        self.feature_idx = None\n",
        "        self.feature_value = None\n",
        "        self.node_prediction = None\n",
        "\n",
        "    def gini_best_score(self, y, possible_splits):\n",
        "        best_gain = -np.inf\n",
        "        best_idx = 0\n",
        "\n",
        "        # TODO find position of best data split --> DOING IT NOT FINISHED !!\n",
        "\n",
        "        n_total = y.shape[0]\n",
        "        n_pos = np.sum(y)\n",
        "        n_neg = n_total - n_pos\n",
        "\n",
        "        base_gini = 1 - (n_pos / n_total) ** 2 - (n_neg / n_total) ** 2\n",
        "\n",
        "\n",
        "        for idx in possible_splits:\n",
        "          left_y = y[: idx + 1]\n",
        "          right_y = y[idx + 1 :]\n",
        "          left_total = left_y.shape[0]\n",
        "          left_pos = np.sum(left_y)\n",
        "          left_neg = left_total - left_pos\n",
        "          right_total = right_y.shape[0]\n",
        "          right_pos = np.sum(right_y)\n",
        "          right_neg = right_total - right_pos\n",
        "\n",
        "\n",
        "        return best_idx, best_gain\n",
        "\n",
        "    def split_data(self, X, y, idx, val):\n",
        "        left_mask = X[:, idx] < val\n",
        "        return (X[left_mask], y[left_mask]), (X[~left_mask], y[~left_mask])\n",
        "\n",
        "    def find_possible_splits(self, data):\n",
        "        possible_split_points = []\n",
        "        for idx in range(data.shape[0] - 1):\n",
        "            if data[idx] != data[idx + 1]:\n",
        "                possible_split_points.append(idx)\n",
        "        return possible_split_points\n",
        "\n",
        "    def find_best_split(self, X, y, feature_subset):\n",
        "        best_gain = -np.inf\n",
        "        best_split = None\n",
        "\n",
        "        # TODO implement feature selection ---> READY !!!\n",
        "\n",
        "        feature_indices = np.arange(X.shape[1])\n",
        "        if feature_subset is not None:\n",
        "          np.random.shuffle(feature_indices)\n",
        "          feature_indices = feature_indices[:feature_subset]\n",
        "\n",
        "        for d in range(X.shape[1]):\n",
        "            order = np.argsort(X[:, d])\n",
        "            y_sorted = y[order]\n",
        "            possible_splits = self.find_possible_splits(X[order, d])\n",
        "            idx, value = self.gini_best_score(y_sorted, possible_splits)\n",
        "            if value > best_gain:\n",
        "                best_gain = value\n",
        "                best_split = (d, [idx, idx + 1])\n",
        "\n",
        "        if best_split is None:\n",
        "            return None, None\n",
        "\n",
        "        best_value = np.mean(X[best_split[1], best_split[0]])\n",
        "\n",
        "        return best_split[0], best_value\n",
        "\n",
        "    def predict(self, x):\n",
        "        if self.feature_idx is None:\n",
        "            return self.node_prediction\n",
        "        if x[self.feature_idx] < self.feature_value:\n",
        "            return self.left_child.predict(x)\n",
        "        else:\n",
        "            return self.right_child.predict(x)\n",
        "\n",
        "    def train(self, X, y, params):\n",
        "\n",
        "        self.node_prediction = np.mean(y)\n",
        "        if X.shape[0] == 1 or self.node_prediction == 0 or self.node_prediction == 1:\n",
        "            return True\n",
        "\n",
        "        self.feature_idx, self.feature_value = self.find_best_split(X, y, params[\"feature_subset\"])\n",
        "        if self.feature_idx is None:\n",
        "            return True\n",
        "\n",
        "        (X_left, y_left), (X_right, y_right) = self.split_data(X, y, self.feature_idx, self.feature_value)\n",
        "\n",
        "        if X_left.shape[0] == 0 or X_right.shape[0] == 0:\n",
        "            self.feature_idx = None\n",
        "            return True\n",
        "\n",
        "        # max tree depth\n",
        "        if params[\"depth\"] is not None:\n",
        "            params[\"depth\"] -= 1\n",
        "        if params[\"depth\"] == 0:\n",
        "            self.feature_idx = None\n",
        "            return True\n",
        "\n",
        "        # create new nodes\n",
        "        self.left_child, self.right_child = Node(), Node()\n",
        "        self.left_child.train(X_left, y_left, copy.deepcopy(params))\n",
        "        self.right_child.train(X_right, y_right, copy.deepcopy(params))\n"
      ],
      "metadata": {
        "id": "KfqcFU7Y2Qnr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "random_fores.py"
      ],
      "metadata": {
        "id": "Sd9-CTOW2yYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "class RandomForest:\n",
        "    def __init__(self, params):\n",
        "        self.forest = []\n",
        "        self.params = defaultdict(lambda: None, params)\n",
        "\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for _ in range(self.params[\"ntrees\"]):\n",
        "            X_bagging, y_bagging = self.bagging(X,y)\n",
        "            tree = DecisionTree(self.params)\n",
        "            tree.train(X_bagging, y_bagging)\n",
        "            self.forest.append(tree)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predicted = self.predict(X)\n",
        "        predicted = [round(p) for p in predicted]\n",
        "        print(f\"Accuracy: {round(np.mean(predicted==y),2)}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        tree_predictions = []\n",
        "        for tree in self.forest:\n",
        "            tree_predictions.append(tree.predict(X))\n",
        "        forest_predictions = list(map(lambda x: sum(x)/len(x), zip(*tree_predictions)))\n",
        "        return forest_predictions\n",
        "\n",
        "    def bagging(self, X, y):\n",
        "        X_selected, y_selected = None, None\n",
        "        # TODO implement bagging ---> DONE\n",
        "\n",
        "        indices = np.random.randint(0, len(X), len(X))\n",
        "        X_selected = X[indices]\n",
        "        y_selected = y[indices]\n",
        "        return X_selected, y_selected\n"
      ],
      "metadata": {
        "id": "u2Xu6QCy2Thd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    np.random.seed(123)\n",
        "\n",
        "    train_data, test_data = load_titanic()\n",
        "\n",
        "    dt = DecisionTree({\"depth\": 14})\n",
        "    dt.train(*train_data)\n",
        "    dt.evaluate(*train_data)\n",
        "    dt.evaluate(*test_data)\n",
        "\n",
        "    rf = RandomForest({\"ntrees\": 10, \"feature_subset\": 2, \"depth\": 14})\n",
        "    rf.train(*train_data)\n",
        "    rf.evaluate(*train_data)\n",
        "    rf.evaluate(*test_data)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX2Rql9b2VRN",
        "outputId": "83a3ed1b-2a13-4d8f-c92a-30e02ae2055c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.59\n",
            "Accuracy: 0.61\n",
            "Accuracy: 0.59\n",
            "Accuracy: 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JtFKLb1d4qDo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}