{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN03OMqeh5MY4dMBI4foGtN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukaszplust/Machine-Learning/blob/main/Lab_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install node"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjt6_Ole1f7i",
        "outputId": "4f4b077a-30f2-419f-cd9f-9165cf017508"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting node\n",
            "  Downloading node-1.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting odict>=1.9.0 (from node)\n",
            "  Downloading odict-1.9.0-py3-none-any.whl (15 kB)\n",
            "Collecting plumber>=1.5 (from node)\n",
            "  Downloading plumber-1.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from node) (67.7.2)\n",
            "Collecting zope.component (from node)\n",
            "  Downloading zope.component-6.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.deferredimport (from node)\n",
            "  Downloading zope.deferredimport-5.0-py3-none-any.whl (10.0 kB)\n",
            "Collecting zope.deprecation (from node)\n",
            "  Downloading zope.deprecation-5.0-py3-none-any.whl (10 kB)\n",
            "Collecting zope.lifecycleevent (from node)\n",
            "  Downloading zope.lifecycleevent-5.0-py3-none-any.whl (18 kB)\n",
            "Collecting zope.event (from zope.component->node)\n",
            "  Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting zope.hookable>=4.2.0 (from zope.component->node)\n",
            "  Downloading zope.hookable-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Collecting zope.interface>=5.3 (from zope.component->node)\n",
            "  Downloading zope.interface-6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.proxy (from zope.deferredimport->node)\n",
            "  Downloading zope.proxy-5.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zope.interface, zope.hookable, zope.event, zope.deprecation, plumber, odict, zope.proxy, zope.lifecycleevent, zope.component, zope.deferredimport, node\n",
            "Successfully installed node-1.2.1 odict-1.9.0 plumber-1.7 zope.component-6.0 zope.deferredimport-5.0 zope.deprecation-5.0 zope.event-5.0 zope.hookable-6.0 zope.interface-6.2 zope.lifecycleevent-5.0 zope.proxy-5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from decision_tree import DecisionTree\n",
        "from random_forest_solution import RandomForest\n",
        "from load_data import generate_data, load_titanic\n",
        "from node_solution import Node"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "XddpYuEX29au",
        "outputId": "bfed20b5-aaf6-4356-c903-4714088baf6c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'decision_tree'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-304c7cf54b6a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdecision_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom_forest_solution\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mload_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_titanic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnode_solution\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'decision_tree'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "decision_tree"
      ],
      "metadata": {
        "id": "veRK1zk72fHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N0wY99Tu1Rw9"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, params):\n",
        "        self.root_node = Node()\n",
        "        self.params = defaultdict(lambda: None, params)\n",
        "\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.root_node.train(X, y, self.params)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predicted = self.predict(X)\n",
        "        predicted = [round(p) for p in predicted]\n",
        "        print(f\"Accuracy: {round(np.mean(predicted==y),2)}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        prediction = []\n",
        "        for x in X:\n",
        "            prediction.append(self.root_node.predict(x))\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load_data.py"
      ],
      "metadata": {
        "id": "qyGtGCMw2dJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "def generate_data():\n",
        "    TRAIN_SAMPLES = 100\n",
        "    TEST_SAMPLES = 20\n",
        "    FEATURE_DIM = 5\n",
        "\n",
        "    X_train = np.random.rand(TRAIN_SAMPLES, FEATURE_DIM)\n",
        "    y_train = np.random.binomial(1, 0.5, TRAIN_SAMPLES)\n",
        "    X_test = np.random.rand(TEST_SAMPLES, FEATURE_DIM)\n",
        "    y_test = np.random.binomial(1, 0.5, TEST_SAMPLES)\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "\n",
        "def load_titanic():\n",
        "    data = pd.read_csv(\"titanic.csv\")\n",
        "    data = data[[\"Pclass\", \"Fare\", \"Parch\", \"SibSp\", \"Age\", \"Sex\", \"Survived\"]]\n",
        "    data = data.dropna().reset_index(drop=True)\n",
        "    data[\"Sex\"] = [1 if sex == \"female\" else 0 for sex in data[\"Sex\"]]\n",
        "    test_idx = np.random.choice(range(data.shape[0]), round(0.2*data.shape[0]), replace=False)\n",
        "    data_test = data.iloc[test_idx, :]\n",
        "    data_train = data.drop(test_idx, axis=0)\n",
        "    X_train = data_train.drop(\"Survived\", axis=1).to_numpy()\n",
        "    y_train = data_train[\"Survived\"].to_numpy()\n",
        "    X_test = data_test.drop(\"Survived\", axis=1).to_numpy()\n",
        "    y_test = data_test[\"Survived\"].to_numpy()\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ],
      "metadata": {
        "id": "53PEGEHF1SmO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main.py"
      ],
      "metadata": {
        "id": "rK0G-ev12acj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    np.random.seed(123)\n",
        "\n",
        "    train_data, test_data = load_titanic()\n",
        "\n",
        "    dt = DecisionTree({\"depth\": 14})\n",
        "    dt.train(*train_data)\n",
        "    dt.evaluate(*train_data)\n",
        "    dt.evaluate(*test_data)\n",
        "\n",
        "    rf = RandomForest({\"ntrees\": 10, \"feature_subset\": 2, \"depth\": 14})\n",
        "    rf.train(*train_data)\n",
        "    rf.evaluate(*train_data)\n",
        "    rf.evaluate(*test_data)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "fBBFBrzl2MWg",
        "outputId": "0271a396-4e18-4753-9290-ee7bec0e2cb4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DecisionTree' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a9f7abfb3071>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-a9f7abfb3071>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_titanic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"depth\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DecisionTree' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "node.py"
      ],
      "metadata": {
        "id": "oEnFWRib2v5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Node:\n",
        "    def __init__(self):\n",
        "        self.left_child = None\n",
        "        self.right_child = None\n",
        "        self.feature_idx = None\n",
        "        self.feature_value = None\n",
        "        self.node_prediction = None\n",
        "\n",
        "    def gini_best_score(self, y, possible_splits):\n",
        "        best_gain = -np.inf\n",
        "        best_idx = 0\n",
        "\n",
        "        # TODO find position of best data split\n",
        "\n",
        "        return best_idx, best_gain\n",
        "\n",
        "    def split_data(self, X, y, idx, val):\n",
        "        left_mask = X[:, idx] < val\n",
        "        return (X[left_mask], y[left_mask]), (X[~left_mask], y[~left_mask])\n",
        "\n",
        "    def find_possible_splits(self, data):\n",
        "        possible_split_points = []\n",
        "        for idx in range(data.shape[0] - 1):\n",
        "            if data[idx] != data[idx + 1]:\n",
        "                possible_split_points.append(idx)\n",
        "        return possible_split_points\n",
        "\n",
        "    def find_best_split(self, X, y, feature_subset):\n",
        "        best_gain = -np.inf\n",
        "        best_split = None\n",
        "\n",
        "        # TODO implement feature selection\n",
        "\n",
        "        for d in range(X.shape[1]):\n",
        "            order = np.argsort(X[:, d])\n",
        "            y_sorted = y[order]\n",
        "            possible_splits = self.find_possible_splits(X[order, d])\n",
        "            idx, value = self.gini_best_score(y_sorted, possible_splits)\n",
        "            if value > best_gain:\n",
        "                best_gain = value\n",
        "                best_split = (d, [idx, idx + 1])\n",
        "\n",
        "        if best_split is None:\n",
        "            return None, None\n",
        "\n",
        "        best_value = np.mean(X[best_split[1], best_split[0]])\n",
        "\n",
        "        return best_split[0], best_value\n",
        "\n",
        "    def predict(self, x):\n",
        "        if self.feature_idx is None:\n",
        "            return self.node_prediction\n",
        "        if x[self.feature_idx] < self.feature_value:\n",
        "            return self.left_child.predict(x)\n",
        "        else:\n",
        "            return self.right_child.predict(x)\n",
        "\n",
        "    def train(self, X, y, params):\n",
        "\n",
        "        self.node_prediction = np.mean(y)\n",
        "        if X.shape[0] == 1 or self.node_prediction == 0 or self.node_prediction == 1:\n",
        "            return True\n",
        "\n",
        "        self.feature_idx, self.feature_value = self.find_best_split(X, y, params[\"feature_subset\"])\n",
        "        if self.feature_idx is None:\n",
        "            return True\n",
        "\n",
        "        (X_left, y_left), (X_right, y_right) = self.split_data(X, y, self.feature_idx, self.feature_value)\n",
        "\n",
        "        if X_left.shape[0] == 0 or X_right.shape[0] == 0:\n",
        "            self.feature_idx = None\n",
        "            return True\n",
        "\n",
        "        # max tree depth\n",
        "        if params[\"depth\"] is not None:\n",
        "            params[\"depth\"] -= 1\n",
        "        if params[\"depth\"] == 0:\n",
        "            self.feature_idx = None\n",
        "            return True\n",
        "\n",
        "        # create new nodes\n",
        "        self.left_child, self.right_child = Node(), Node()\n",
        "        self.left_child.train(X_left, y_left, copy.deepcopy(params))\n",
        "        self.right_child.train(X_right, y_right, copy.deepcopy(params))\n"
      ],
      "metadata": {
        "id": "KfqcFU7Y2Qnr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "random_fores.py"
      ],
      "metadata": {
        "id": "Sd9-CTOW2yYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "class RandomForest:\n",
        "    def __init__(self, params):\n",
        "        self.forest = []\n",
        "        self.params = defaultdict(lambda: None, params)\n",
        "\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for _ in range(self.params[\"ntrees\"]):\n",
        "            X_bagging, y_bagging = self.bagging(X,y)\n",
        "            tree = DecisionTree(self.params)\n",
        "            tree.train(X_bagging, y_bagging)\n",
        "            self.forest.append(tree)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predicted = self.predict(X)\n",
        "        predicted = [round(p) for p in predicted]\n",
        "        print(f\"Accuracy: {round(np.mean(predicted==y),2)}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        tree_predictions = []\n",
        "        for tree in self.forest:\n",
        "            tree_predictions.append(tree.predict(X))\n",
        "        forest_predictions = list(map(lambda x: sum(x)/len(x), zip(*tree_predictions)))\n",
        "        return forest_predictions\n",
        "\n",
        "    def bagging(self, X, y):\n",
        "        X_selected, y_selected = None, None\n",
        "        # TODO implement bagging\n",
        "\n",
        "        return X_selected, y_selected\n"
      ],
      "metadata": {
        "id": "u2Xu6QCy2Thd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jX2Rql9b2VRN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}